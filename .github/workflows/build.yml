name: Build and Deploy (Pages)

on:
  push:
    branches:
      - main
      - test
  workflow_dispatch:

permissions:
  contents: read
  pages: write
  id-token: write

concurrency:
  group: pages
  cancel-in-progress: true

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Hugo
        uses: peaceiris/actions-hugo@v2
        with:
          hugo-version: '0.150.0'
          extended: true

      - name: Configure Pages
        uses: actions/configure-pages@v5

      - name: Set cache-busting version (appVer)
        run: echo "HUGO_PARAMS_APPVER=${GITHUB_SHA::7}" >> $GITHUB_ENV

      - name: Build site (publishDir=public)
        run: hugo --minify

      - name: Verify cache-busting markers
        run: |
          set -e
          echo "Expected appVer: ${HUGO_PARAMS_APPVER}"
          # 1) HTML root carries the appVer used for cache busting of images/JSON
          grep -q "data-app-ver=${HUGO_PARAMS_APPVER}" public/index.html || {
            echo "ERROR: data-app-ver mismatch or missing in public/index.html";
            exit 1;
          }
          # 2) CSS bundle uses fingerprinted filename
          grep -Eo '/style/bundle.min\.[a-f0-9]{64}\.css' public/index.html >/dev/null || {
            echo "ERROR: CSS bundle fingerprint not found in index.html";
            exit 1;
          }
          # 3) JS bundle uses fingerprinted filename
          grep -Eo '/script/bundle.min\.[a-f0-9]{64}\.js' public/index.html >/dev/null || {
            echo "ERROR: JS bundle fingerprint not found in index.html";
            exit 1;
          }

      - name: Validate SRI references in generated HTML
        run: |
          python - << 'PY'
          import os, re, sys, base64, hashlib
          from urllib.parse import urlparse

          root = 'public'
          problems = []

          def to_local(url: str) -> str:
              # Map a URL to a local file under public/.
              # Handles GitHub Pages paths by stripping the first segment if needed.
              path = urlparse(url).path or url
              path = path.lstrip('/')
              cand = os.path.join(root, path)
              if os.path.exists(cand):
                  return cand
              if '/' in path:
                  _, rest = path.split('/', 1)
                  cand2 = os.path.join(root, rest)
                  if os.path.exists(cand2):
                      return cand2
              return cand

          # Scan all HTML under public/
          for dirpath, _, filenames in os.walk(root):
              for fn in filenames:
                  if not fn.endswith('.html'):
                      continue
                  fp = os.path.join(dirpath, fn)
                  html = open(fp, 'rb').read().decode('utf-8', errors='ignore')
                  # Find stylesheet links with integrity
                  for m in re.finditer(r'<link[^>]+rel=["\\"]stylesheet["\\"][^>]+href=["\\"]([^"\\"]+)["\\"][^>]+integrity=["\\"](sha256-[^"\\"]+)["\\"]', html, re.I):
                      url, integrity = m.group(1), m.group(2)
                      local = to_local(url)
                      if not os.path.exists(local):
                          problems.append(f"Missing CSS asset: {url} -> {local}")
                          continue
                      data = open(local, 'rb').read()
                      digest = base64.b64encode(hashlib.sha256(data).digest()).decode('ascii')
                      if integrity != f'sha256-{digest}':
                          problems.append(f"SRI mismatch CSS: {url}\n expected {integrity}\n   actual sha256-{digest}")
                  # Find scripts with integrity
                  for m in re.finditer(r'<script[^>]+src=["\\"]([^"\\"]+)["\\"][^>]+integrity=["\\"](sha256-[^"\\"]+)["\\"]', html, re.I):
                      url, integrity = m.group(1), m.group(2)
                      local = to_local(url)
                      if not os.path.exists(local):
                          problems.append(f"Missing JS asset: {url} -> {local}")
                          continue
                      data = open(local, 'rb').read()
                      digest = base64.b64encode(hashlib.sha256(data).digest()).decode('ascii')
                      if integrity != f'sha256-{digest}':
                          problems.append(f"SRI mismatch JS: {url}\n expected {integrity}\n   actual sha256-{digest}")

          if problems:
              print('\n'.join(problems))
              sys.exit(1)
          else:
              print('SRI validation passed for CSS/JS references')
          PY

      - name: Upload Pages artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: ./public

  deploy:
    needs: build
    runs-on: ubuntu-latest
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    steps:
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
